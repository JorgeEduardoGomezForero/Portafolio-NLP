{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ-VfNtOyJbsaxu43Kztf_cv1mgBG6ZIQZEVw&usqp=CAU'>\n",
    "\n",
    "# Procesamiento de Lenguage Natural\n",
    "\n",
    "## Taller 04: Feature Engineering \n",
    "###    Jorge Eduardo Gomez Forero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 1: Pre-Procesamiento\n",
    "\n",
    "**1.1 Leer el archivo `dialogos.csv` usando `pandas`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la variable ruta para establecer la ubicación del archivo de trabajo, con el objetivo de reducir la escritura del código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"C:/03_Jorge/01_Especialización_Analitica/02_Semestre/04 Electiva Fundamentos NLP/20200905/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa la libreria pandas para realiza la lectura del archivo con extensión .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Locución\n",
      "0                                       Francamente no\n",
      "1    Lo del canadiense. Por favor, como que vosotro...\n",
      "2    Tienes razón. A lo mejor así te liberas de tu ...\n",
      "3                                      Pues, tú sabrás\n",
      "4                              Para mí que fue Krieger\n",
      "..                                                 ...\n",
      "954                        Yo qué sé, digo yo qué será\n",
      "955  Lo han entendido mal. Las joyas que venden en ...\n",
      "956                            Oooo... Me llamo Vivian\n",
      "957                  ¿De dónde? ¿Del coño de tu madre?\n",
      "958                       Ah, sí esto podría funcionar\n",
      "\n",
      "[959 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(ruta+\"dialogos.csv\", sep=\",\",encoding='utf-8')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Crear una nueva columna con el texto en minúscula a partir de la columna \"Locución\", sin caracteres especiales, sin números y sin palabras vacias.**\n",
    "\n",
    "Con la función lower() se cambia a minuscula el texto.\n",
    "\n",
    "Para comenzar a limpiar la información, se utiliza la función sub de la libreria re (expresiones regulares), y con el patron r\"[\\W\\d_]+\" se reemplazaran los caracteres especiales por espacio.\n",
    "\n",
    "La función strip() permite eliminar los espacios al comienzo y final.\n",
    "\n",
    "Finalmente con la función stopwords.words('spanish') se Tokeniza, es decir, se eliminaran las palabras consideradas como vacias (palabras que no tienen un significado por si solas, sino que modifican o acompañan a otras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[es:0.9999961400660539]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jgome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Locución</th>\n",
       "      <th>pre_procesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Francamente no</td>\n",
       "      <td>francamente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lo del canadiense. Por favor, como que vosotro...</td>\n",
       "      <td>canadiense favor tiraríais allí si pudieseis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tienes razón. A lo mejor así te liberas de tu ...</td>\n",
       "      <td>razón mejor así liberas energía nagativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pues, tú sabrás</td>\n",
       "      <td>pues sabrás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Para mí que fue Krieger</td>\n",
       "      <td>krieger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Yo qué sé, digo yo qué será</td>\n",
       "      <td>sé digo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Lo han entendido mal. Las joyas que venden en ...</td>\n",
       "      <td>entendido mal joyas venden canales siquiera in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>Oooo... Me llamo Vivian</td>\n",
       "      <td>oooo llamo vivian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>¿De dónde? ¿Del coño de tu madre?</td>\n",
       "      <td>dónde coño madre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Ah, sí esto podría funcionar</td>\n",
       "      <td>ah podría funcionar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>959 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Locución  \\\n",
       "0                                       Francamente no   \n",
       "1    Lo del canadiense. Por favor, como que vosotro...   \n",
       "2    Tienes razón. A lo mejor así te liberas de tu ...   \n",
       "3                                      Pues, tú sabrás   \n",
       "4                              Para mí que fue Krieger   \n",
       "..                                                 ...   \n",
       "954                        Yo qué sé, digo yo qué será   \n",
       "955  Lo han entendido mal. Las joyas que venden en ...   \n",
       "956                            Oooo... Me llamo Vivian   \n",
       "957                  ¿De dónde? ¿Del coño de tu madre?   \n",
       "958                       Ah, sí esto podría funcionar   \n",
       "\n",
       "                                         pre_procesado  \n",
       "0                                          francamente  \n",
       "1         canadiense favor tiraríais allí si pudieseis  \n",
       "2             razón mejor así liberas energía nagativa  \n",
       "3                                          pues sabrás  \n",
       "4                                              krieger  \n",
       "..                                                 ...  \n",
       "954                                            sé digo  \n",
       "955  entendido mal joyas venden canales siquiera in...  \n",
       "956                                  oooo llamo vivian  \n",
       "957                                   dónde coño madre  \n",
       "958                                ah podría funcionar  \n",
       "\n",
       "[959 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crea nueva columna con la información de la columna 'Locución':\n",
    "data['pre_procesado'] = data['Locución'].values\n",
    "#cambia todas las palabras de la columna 'pre_procesado' a minuscula (estandarización):\n",
    "data['pre_procesado'] = data['pre_procesado'].str.lower()\n",
    "\n",
    "#Se importa esta libreria dado que contiene las expresiones regulares.\n",
    "import re\n",
    "#Eliminar expresiones regulares, con el objetivo de mantener unicamente palabras\n",
    "for indice_fila, fila in data.iterrows():\n",
    "    text = fila.pre_procesado\n",
    "    text = re.sub(r\"[\\W\\d_]+\",\" \",text)\n",
    "    data.loc[indice_fila,'pre_procesado'] = text.strip()\n",
    "\n",
    "#Esta libreria permite conocer el porcentaje de el o los idiomas en los que se encuentra la información:\n",
    "from langdetect import detect, detect_langs\n",
    "vocabulario = data['pre_procesado'].str.cat(sep=\" \")\n",
    "print(detect_langs(vocabulario))  \n",
    "        \n",
    "#Esta libreria se importa una sola vez, sin embargo se deja como tema ilustrativo para recordar de donde proviene 'stopwords':\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Conociendo el idioma se asigna el listado de palabras vacias segun corresponda\n",
    "nstopwords_sp = stopwords.words('spanish')\n",
    "\n",
    "#Elimina todas las palabras vacías\n",
    "data['pre_procesado'] = data['pre_procesado'].apply(lambda x: ' '.join([Word for Word in x.split() if Word not in (nstopwords_sp)]))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 2: Representación vectorial\n",
    "\n",
    "**2.1 Crear una bolsa de palabras (BoW) del corpus usando la columna pre-procesada.**\n",
    "\n",
    "**2.2 ¿Cuántas palabras hay en el vocabulario? (Usando la función de `sklearn`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2115"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#libreria de aprendizaje automático\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Se crea vector de transfomación\n",
    "count_vect = CountVectorizer()\n",
    "#con fit adquiere el vocabulario y trasnforma cada texto a la representación vectorial\n",
    "bow_pre_procesado = count_vect.fit_transform(data['pre_procesado'].values)\n",
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 3:\n",
    "\n",
    "**3.1 ¿En qué casos es buena idea tomar en la cuenta la frecuencia de las palabras para la bolsa de palabras?**\n",
    "\n",
    "  Es de gran ayuda en las situaciones en las que se necesita identificar la frecuencia de las palabras ingnorando el orden en el que se encuentren, lo cual nos permitira identificar patrones que a su vez nos facilitara la construcción de segmentos o grupos de analisis.\n",
    "  \n",
    "**3.2 ¿Cuándo es una mejor idea usar una bolsa de n-gramas en vez de una bolsa de palabras?**\n",
    "\n",
    "Es importante utilizar los n-gramas para entender el contexto y obtener el significado correcto.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
